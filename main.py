import streamlit as st
import requests
import base64
from dotenv import load_dotenv
import openai
from diffusers import StableDiffusionPipeline
import torch
from PIL import Image
from streamlit_chat import message
from utils import get_initial_message

load_dotenv()
openai.api_key = "OPENAI_KEY"


# function to generate AI based images using OpenAI Dall-E
def generate_images_using_openai(text):
    response = openai.Image.create(prompt=text, n=1, size="512x512")
    image_url = response['data'][0]['url']
    return image_url


# function to generate AI based images using Huggingface Diffusers
def generate_images_using_huggingface_diffusers(text):
    pipe = StableDiffusionPipeline.from_pretrained("stable-diffusion-v1-5", torch_dtype=torch.float16)
    pipe = pipe.to("cuda")
    prompt = text
    image = pipe(prompt).images[0]
    return image


# Streamlit Code
choice = st.sidebar.selectbox("Select your choice", ["Home", "DALL-E", "Huggingface Diffusers", "AI Prompt Generator"])

if choice == "AI Prompt Generator":
    # chatbot
    st.title("Prompt Helping BOT : (Prototype)")
    st.subheader("-By Rahul Sharma")

    # Set OpenAI API key from Streamlit secrets
    openai.api_key = "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"

    # Set a default model
    if "openai_model" not in st.session_state:
        st.session_state["openai_model"] = "gpt-3.5-turbo"

    # Initialize chat history
    if 'messages' not in st.session_state:
        st.session_state['messages'] = get_initial_message()

    # Display chat messages from history on app rerun
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Accept user input
    if prompt := st.chat_input("Your Imagination Begins Here"):
        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "content": prompt})
        # Display user message in chat message container
        with st.chat_message("user"):
            st.markdown(prompt)
        # Display assistant response in chat message container
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            for response in openai.ChatCompletion.create(
                    model=st.session_state["openai_model"],
                    messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
                    stream=True,
            ):
                full_response += response.choices[0].delta.get("content", "")
                message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})

elif choice == "Home":
    st.title("AI Image Generation App")
    st.subheader('-By Rahul Sharma')
    with st.expander("About the App"):
        st.write("This is a simple image generation app that uses AI to generates images from text prompt.")


elif choice == "DALL-E":
    st.title("Image generation using Open AI's DALL-E")
    st.subheader('-By Rahul Sharma')
    input_prompt = st.text_input("Enter your text prompt")
    if input_prompt is not None:
        if st.button("Generate Image"):
            image_url = generate_images_using_openai(input_prompt)
            st.image(image_url, caption="Generated by DALL-E")

elif choice == "Huggingface Diffusers":
    st.title("Image generation using Huggingface Diffusers")
    st.subheader('-By Rahul Sharma')
    input_prompt = st.text_input("Enter your text prompt")
    if input_prompt is not None:
        if st.button("Generate Image"):
            image_output = generate_images_using_huggingface_diffusers(input_prompt)
            st.info("Generating image.....")
            st.success("Image Generated Successfully")
            st.image(image_output, caption="Generated by Huggingface Diffusers")
